{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2db25e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<uppercase>', 'bu', ' ', 'gurbet', ' ', 'yol', 'lar', 'ı', ' ', 'aman', ' ', 'zaman', ' ', 'geç', 'm', 'i', 'yor', ' ', 'aman', ' ', 'biz', 'i', ' ', 'perişan', '.', ' ', 'eder', ' ', 'bu', ' ', 'yol', 'da', 'ki', ' ', 'çocuk', 'lar']\n",
      "[0, 2503, 2, 3788, 2, 2582, 20000, 20034, 2, 19518, 2, 2514, 2, 2716, 20039, 20033, 20041, 2, 19518, 2, 2595, 20033, 2, 6750, 31897, 2, 2548, 2, 2503, 2, 2582, 20024, 20059, 2, 206, 20000, 6]\n",
      "Bu gurbet yolları aman zaman geçmiyor aman bizi perişan. eder bu yoldaki çocuklar\n"
     ]
    }
   ],
   "source": [
    "from turkish_tokenizer import HFTurkishTokenizer\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = HFTurkishTokenizer()\n",
    "\n",
    "# Tokenize text\n",
    "text = \"Bu gurbet yolları aman zaman geçmiyor aman bizi perişan. eder bu yoldaki çocuklar\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "# Encode text\n",
    "encoded = tokenizer.encode(text, add_special_tokens=True)\n",
    "print(encoded)\n",
    "\n",
    "# Decode back to text\n",
    "decoded = tokenizer.decode(encoded, skip_special_tokens=True)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b860fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([    0,  2503,     2,  2577,     2,  2669,     2,  2626, 20033,     2,\n",
      "        19482,     2,  2937, 20023, 20040, 20032, 31897,     2, 19498,     2,\n",
      "         2544,     2,  2502, 20012,     2,  3585,     2,   198, 20031,     6,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5,     5,     5,\n",
      "            5,     5,     5,     5,     5,     5,     5,     5]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "model_inputs = tokenizer(\n",
    "    \"Bu cümle model girişi için hazırlanacak. ama önemli olan dans etmek\",\n",
    "    add_special_tokens=True,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "print(model_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65da4002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3b8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
